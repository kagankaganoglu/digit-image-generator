# -*- coding: utf-8 -*-
"""train_cgan_mnist.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qTWYuWyjBUzQ8G1v08fJKCdw1qMF-gAy
"""

import torch
from torch import nn, optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import os

# ─── CONFIG ────────────────────────────────────────────────────────────────
BATCH_SIZE      = 128
Z_DIM           = 100            # noise vector size
NUM_CLASSES     = 10
IMG_SIZE        = 28
LR              = 2e-4
EPOCHS          = 30
DEVICE          = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
SAVE_PATH       = 'cgan_generator.pth'
# ────────────────────────────────────────────────────────────────────────────

# ─── DATA ─────────────────────────────────────────────────────────────────
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])
ds = datasets.MNIST(root='mnist_data', train=True, download=True, transform=transform)
loader = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)
# ────────────────────────────────────────────────────────────────────────────

# ─── MODEL DEFS ────────────────────────────────────────────────────────────
class Generator(nn.Module):
    def __init__(self):
        super().__init__()
        # Input: noise Z concatenated with one-hot label (size 100+10)
        self.net = nn.Sequential(
            nn.Linear(Z_DIM + NUM_CLASSES, 256),
            nn.LeakyReLU(0.2, True),
            nn.Linear(256, 512),
            nn.LeakyReLU(0.2, True),
            nn.Linear(512, 1024),
            nn.LeakyReLU(0.2, True),
            nn.Linear(1024, IMG_SIZE*IMG_SIZE),
            nn.Tanh()
        )

    def forward(self, z, labels):
        x = torch.cat([z, labels], dim=1)
        img = self.net(x)
        return img.view(-1, 1, IMG_SIZE, IMG_SIZE)

class Discriminator(nn.Module):
    def __init__(self):
        super().__init__()
        # Input: flattened image + one-hot label
        self.net = nn.Sequential(
            nn.Linear(IMG_SIZE*IMG_SIZE + NUM_CLASSES, 512),
            nn.LeakyReLU(0.2, True),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2, True),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )

    def forward(self, img, labels):
        x = torch.cat([img.view(img.size(0), -1), labels], dim=1)
        return self.net(x)
# ────────────────────────────────────────────────────────────────────────────

# ─── HELPERS ────────────────────────────────────────────────────────────────
def one_hot(labels):
    return torch.eye(NUM_CLASSES, device=DEVICE)[labels]

def sample_noise_and_labels(batch):
    z = torch.randn(batch, Z_DIM, device=DEVICE)
    lbl = torch.randint(0, NUM_CLASSES, (batch,), device=DEVICE)
    return z, one_hot(lbl)
# ────────────────────────────────────────────────────────────────────────────

import tqdm
from tqdm import tqdm
# ─── TRAIN LOOP ─────────────────────────────────────────────────────────────
G = Generator().to(DEVICE)
D = Discriminator().to(DEVICE)
opt_G = optim.Adam(G.parameters(), lr=LR, betas=(0.5, 0.999))
opt_D = optim.Adam(D.parameters(), lr=LR, betas=(0.5, 0.999))
criterion = nn.BCELoss()

for epoch in tqdm(range(1, EPOCHS+1)):
    for real_imgs, real_lbls in loader:
        bs = real_imgs.size(0)
        real_imgs, real_lbls = real_imgs.to(DEVICE), real_lbls.to(DEVICE)
        real_onehot = one_hot(real_lbls)
        real_target = torch.ones(bs, 1, device=DEVICE)
        fake_target = torch.zeros(bs, 1, device=DEVICE)

        # — Train Discriminator —
        opt_D.zero_grad()
        # real
        out_real = D(real_imgs, real_onehot)
        loss_real = criterion(out_real, real_target)
        # fake
        z, fake_onehot = sample_noise_and_labels(bs)
        fake_imgs = G(z, fake_onehot).detach()
        out_fake = D(fake_imgs, fake_onehot)
        loss_fake = criterion(out_fake, fake_target)
        loss_D = (loss_real + loss_fake) / 2
        loss_D.backward()
        opt_D.step()

        # — Train Generator —
        opt_G.zero_grad()
        z, gen_onehot = sample_noise_and_labels(bs)
        gen_imgs = G(z, gen_onehot)
        # trick discriminator to think these are real
        out = D(gen_imgs, gen_onehot)
        loss_G = criterion(out, real_target)
        loss_G.backward()
        opt_G.step()

    print(f"Epoch {epoch}/{EPOCHS}  D-loss: {loss_D.item():.4f}  G-loss: {loss_G.item():.4f}")

# ─── SAVE GENERATOR ───────────────────────────────────────────────────────────
torch.save(G.state_dict(), SAVE_PATH)
print(f"Generator saved to {SAVE_PATH}")

import torch
import matplotlib.pyplot as plt

# ─── CONFIG ─────────────────────────────────────────────────────
MODEL_PATH = 'cgan_generator.pth'   # path to your saved generator
Z_DIM      = 100
NUM_CLASSES= 10
DEVICE     = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
# ────────────────────────────────────────────────────────────────

# 1) Load model
G = Generator().to(DEVICE).eval()
G.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))

# 2) Prepare one noise+label per digit
zs     = torch.randn(NUM_CLASSES, Z_DIM, device=DEVICE)
labels = torch.arange(NUM_CLASSES, device=DEVICE)
one_hot = torch.eye(NUM_CLASSES, device=DEVICE)[labels]

# 3) Generate
with torch.no_grad():
    imgs = G(zs, one_hot).cpu().squeeze(1)   # → (10, 28, 28)

# 4) Plot
fig, axes = plt.subplots(2, 5, figsize=(10, 4))
axes = axes.flatten()
for i, ax in enumerate(axes):
    ax.imshow((imgs[i] + 1) / 2, cmap='gray', vmin=0, vmax=1)  # rescale from [-1,1] → [0,1]
    ax.set_title(f"Digit {i}")
    ax.axis('off')

plt.tight_layout()
plt.show()

